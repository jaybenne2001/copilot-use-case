{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "introduction",
   "metadata": {},
   "source": [
    "# Azure Medallion Data Pipeline Setup\n",
    "\n",
    "This notebook will guide you through setting up the necessary Azure infrastructure for a medallion-style data pipeline. We'll use Azure CLI commands within this notebook to create resources such as:\n",
    "\n",
    "- **Resource Group**\n",
    "- **Storage Account** with containers for **Bronze**, **Silver**, and **Gold** layers\n",
    "- **Azure Data Factory**\n",
    "- **Azure Databricks Workspace**\n",
    "- *(Optional)* **Azure Key Vault**\n",
    "\n",
    "**Prerequisites:**\n",
    "\n",
    "- Azure CLI installed and configured\n",
    "- Azure account with sufficient permissions\n",
    "- Jupyter extension installed in VS Code\n",
    "\n",
    "**Note:** This notebook assumes you're running it in a Unix-like environment (e.g., Linux, macOS, or Windows Subsystem for Linux)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "check_azure_cli",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import json\n",
    "\n",
    "# Function to check if Azure CLI is installed\n",
    "def check_azure_cli():\n",
    "    try:\n",
    "        subprocess.run(['az', '--version'], check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        print(\"Azure CLI is installed.\")\n",
    "    except subprocess.CalledProcessError:\n",
    "        print(\"Azure CLI is not installed. Please install it before running this notebook.\")\n",
    "        raise\n",
    "\n",
    "# Check if Azure CLI is installed\n",
    "check_azure_cli()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "user_inputs",
   "metadata": {},
   "source": [
    "## User Inputs\n",
    "\n",
    "Please provide the required information in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "user_input_variables",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the placeholder values with your actual Azure resource details.\n",
    "\n",
    "# Resource Group Name\n",
    "RESOURCE_GROUP = 'MedallionDataPipelineRG'  # e.g., 'MyResourceGroup'\n",
    "\n",
    "# Azure Region\n",
    "LOCATION = 'eastus'  # e.g., 'eastus', 'westus2'\n",
    "\n",
    "# Storage Account Name (must be globally unique, 3-24 lowercase letters and numbers)\n",
    "STORAGE_ACCOUNT_NAME = 'medallionstorage123'  # e.g., 'mystorageaccount'\n",
    "\n",
    "# Data Factory Name\n",
    "DATA_FACTORY_NAME = 'MedallionADF'  # e.g., 'MyDataFactory'\n",
    "\n",
    "# Databricks Workspace Name\n",
    "DATABRICKS_WORKSPACE = 'MedallionDatabricksWS'  # e.g., 'MyDatabricksWorkspace'\n",
    "\n",
    "# Create Azure Key Vault?\n",
    "CREATE_KEY_VAULT = True  # Set to False if you don't want to create a Key Vault\n",
    "\n",
    "# Key Vault Name (if CREATE_KEY_VAULT is True)\n",
    "KEY_VAULT_NAME = 'MedallionKeyVault123'  # e.g., 'MyKeyVault'\n",
    "\n",
    "# Ensure storage account name is lowercase and between 3-24 characters\n",
    "STORAGE_ACCOUNT_NAME = STORAGE_ACCOUNT_NAME.lower()\n",
    "if len(STORAGE_ACCOUNT_NAME) < 3 or len(STORAGE_ACCOUNT_NAME) > 24:\n",
    "    raise ValueError(\"Storage account name must be between 3 and 24 characters.\")\n",
    "\n",
    "print(\"You have provided the following information:\")\n",
    "print(\"--------------------------------------------\")\n",
    "print(f\"Resource Group Name       : {RESOURCE_GROUP}\")\n",
    "print(f\"Location                  : {LOCATION}\")\n",
    "print(f\"Storage Account Name      : {STORAGE_ACCOUNT_NAME}\")\n",
    "print(f\"Data Factory Name         : {DATA_FACTORY_NAME}\")\n",
    "print(f\"Databricks Workspace Name : {DATABRICKS_WORKSPACE}\")\n",
    "if CREATE_KEY_VAULT:\n",
    "    print(f\"Key Vault Name            : {KEY_VAULT_NAME}\")\n",
    "print(\"--------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confirm_inputs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm the inputs\n",
    "confirm = input('Is this information correct? (yes/no): ')\n",
    "if confirm.lower() != 'yes':\n",
    "    raise Exception('Setup aborted by the user.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "azure_login",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Azure login status\n",
    "print(\"Checking Azure login status...\")\n",
    "try:\n",
    "    subprocess.run(['az', 'account', 'show'], check=True, stdout=subprocess.PIPE)\n",
    "    print(\"Already logged in to Azure.\")\n",
    "except subprocess.CalledProcessError:\n",
    "    print(\"You are not logged in to Azure CLI. Please log in.\")\n",
    "    subprocess.run(['az', 'login'], check=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "create_resource_group",
   "metadata": {},
   "source": [
    "## Create Resource Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create_rg",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating Resource Group...\")\n",
    "subprocess.run([\n",
    "    'az', 'group', 'create',\n",
    "    '--name', RESOURCE_GROUP,\n",
    "    '--location', LOCATION\n",
    "], check=True)\n",
    "print(\"Resource Group created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "create_storage_account",
   "metadata": {},
   "source": [
    "## Create Storage Account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create_storage",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating Storage Account...\")\n",
    "subprocess.run([\n",
    "    'az', 'storage', 'account', 'create',\n",
    "    '--name', STORAGE_ACCOUNT_NAME,\n",
    "    '--resource-group', RESOURCE_GROUP,\n",
    "    '--location', LOCATION,\n",
    "    '--sku', 'Standard_LRS',\n",
    "    '--kind', 'StorageV2',\n",
    "    '--hierarchical-namespace', 'true'\n",
    "], check=True)\n",
    "print(\"Storage Account created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "create_blob_containers",
   "metadata": {},
   "source": [
    "## Create Blob Containers for Bronze, Silver, and Gold Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create_containers",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating Blob Containers...\")\n",
    "\n",
    "# Get storage account key\n",
    "result = subprocess.run([\n",
    "    'az', 'storage', 'account', 'keys', 'list',\n",
    "    '--resource-group', RESOURCE_GROUP,\n",
    "    '--account-name', STORAGE_ACCOUNT_NAME,\n",
    "    '--query', '[0].value',\n",
    "    '-o', 'tsv'\n",
    "], check=True, stdout=subprocess.PIPE)\n",
    "ACCOUNT_KEY = result.stdout.decode('utf-8').strip()\n",
    "\n",
    "for container in ['bronze', 'silver', 'gold']:\n",
    "    print(f\"Creating container '{container}'...\")\n",
    "    subprocess.run([\n",
    "        'az', 'storage', 'container', 'create',\n",
    "        '--name', container,\n",
    "        '--account-name', STORAGE_ACCOUNT_NAME,\n",
    "        '--account-key', ACCOUNT_KEY\n",
    "    ], check=True)\n",
    "print(\"Blob Containers created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "create_data_factory",
   "metadata": {},
   "source": [
    "## Create Azure Data Factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create_adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating Azure Data Factory...\")\n",
    "subprocess.run([\n",
    "    'az', 'datafactory', 'create',\n",
    "    '--resource-group', RESOURCE_GROUP,\n",
    "    '--factory-name', DATA_FACTORY_NAME,\n",
    "    '--location', LOCATION\n",
    "], check=True)\n",
    "print(\"Azure Data Factory created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "create_databricks_workspace",
   "metadata": {},
   "source": [
    "## Create Azure Databricks Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create_databricks",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating Azure Databricks Workspace...\")\n",
    "subprocess.run([\n",
    "    'az', 'databricks', 'workspace', 'create',\n",
    "    '--resource-group', RESOURCE_GROUP,\n",
    "    '--name', DATABRICKS_WORKSPACE,\n",
    "    '--location', LOCATION,\n",
    "    '--sku', 'standard'\n",
    "], check=True)\n",
    "print(\"Azure Databricks Workspace created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "create_key_vault",
   "metadata": {},
   "source": [
    "## (Optional) Create Azure Key Vault"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create_keyvault",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CREATE_KEY_VAULT:\n",
    "    print(\"Creating Azure Key Vault...\")\n",
    "    subprocess.run([\n",
    "        'az', 'keyvault', 'create',\n",
    "        '--name', KEY_VAULT_NAME,\n",
    "        '--resource-group', RESOURCE_GROUP,\n",
    "        '--location', LOCATION\n",
    "    ], check=True)\n",
    "    print(\"Azure Key Vault created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "next_steps",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "The basic Azure infrastructure for your medallion-style data pipeline has been set up. Here are the next steps to complete your pipeline configuration:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "databricks_configuration",
   "metadata": {},
   "source": [
    "### 1. Configure Databricks Workspace\n",
    "\n",
    "- Obtain the fully qualified domain name (FQDN) of your Databricks workspace from the Azure Portal.\n",
    "- Generate a Personal Access Token (PAT) in the Databricks UI under **User Settings** > **Access Tokens**.\n",
    "- Store the PAT securely, preferably in Azure Key Vault."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data_factory_linked_services",
   "metadata": {},
   "source": [
    "### 2. Set Up Linked Services in Azure Data Factory\n",
    "\n",
    "- Create linked services for your Storage Account and Databricks workspace.\n",
    "- Use the Storage Account key or reference it from Key Vault.\n",
    "- Configure the Databricks linked service using the workspace URL and PAT."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "create_datasets",
   "metadata": {},
   "source": [
    "### 3. Create Datasets in Azure Data Factory\n",
    "\n",
    "- Define datasets for the Bronze, Silver, and Gold layers.\n",
    "- Specify the container names and paths."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "develop_databricks_notebooks",
   "metadata": {},
   "source": [
    "### 4. Develop Databricks Notebooks\n",
    "\n",
    "- Create notebooks for data transformations:\n",
    "  - **BronzeToSilver**: Read from Bronze, transform, write to Silver.\n",
    "  - **SilverToGold**: Read from Silver, transform, write to Gold.\n",
    "- Use Spark to read and write data, applying necessary transformations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "create_pipelines",
   "metadata": {},
   "source": [
    "### 5. Create Pipelines in Azure Data Factory\n",
    "\n",
    "- Define activities to orchestrate data movement and transformation.\n",
    "- Configure parameters and variables as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "set_up_scheduling",
   "metadata": {},
   "source": [
    "### 6. Set Up Scheduling and Triggers\n",
    "\n",
    "- Determine the frequency and timing of pipeline runs.\n",
    "- Create triggers in Azure Data Factory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "security_and_compliance",
   "metadata": {},
   "source": [
    "### 7. Security and Compliance\n",
    "\n",
    "- Use Azure Key Vault to store secrets.\n",
    "- Implement role-based access control (RBAC).\n",
    "- Ensure compliance with any regulatory requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleanup_resources",
   "metadata": {},
   "source": [
    "## Clean Up Resources\n",
    "\n",
    "To avoid incurring unnecessary charges, you can delete the resource group when it's no longer needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleanup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the following lines to delete the resource group\n",
    "# print(\"Deleting Resource Group...\")\n",
    "# subprocess.run([\n",
    "#     'az', 'group', 'delete',\n",
    "#     '--name', RESOURCE_GROUP,\n",
    "#     '--yes', '--no-wait'\n",
    "# ], check=True)\n",
    "# print(\"Resource Group deleted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "You have successfully set up the Azure infrastructure for your medallion-style data pipeline. Proceed with configuring the remaining components as outlined in the next steps."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
